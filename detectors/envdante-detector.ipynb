{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "blOJ1buw83T9",
      "metadata": {
        "id": "blOJ1buw83T9"
      },
      "source": [
        "# Envisioning Dante - Graphics Detector"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yLERLQAN3pM0",
      "metadata": {
        "id": "yLERLQAN3pM0"
      },
      "source": [
        "## 1 - Read Me First\n",
        "\n",
        "This project is a [Jupyter](https://jupyter.org/) notebook and was\n",
        "designed to run in [Google\n",
        "Colab](https://colab.research.google.com/).  If you are not reading\n",
        "this notebook in Google Colab, click\n",
        "[here](https://colab.research.google.com/github/ox-vgg/demo-notebooks/blob/main/detectors/envdante-detector.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-tfDPTizFHUi",
      "metadata": {
        "id": "-tfDPTizFHUi"
      },
      "source": [
        "### 1.1 - What is, and how to use, a Jupyter notebook\n",
        "\n",
        "A Jupyter notebook is a series of \"cells\".  Each cell contains\n",
        "either text (like this one) or code (like others below).  A cell\n",
        "that contains code will have a \"Run cell\" button on the left side\n",
        "like this \"<img height=\"18rem\" alt=\"The 'Run cell' button in Colab\"\n",
        "src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAQAAAD9CzEMAAABTklEQVRYw+2XMU7DMBRAX6ss3VA7VV25AFNWzsDQXoAzVDlBKw6QDJwhTO3OCVjaka0VXVKJDUVC4jOgiMHYcRx9S0j9f7XfS5x8+xsu8R9iQEpGyY4TgnBiR0lGyqA/fMaaI2LJI2tm4fAxObUV3mRNzjgEP+fcCm/yzLwbPKHwhjdZkPjiR2w64wVhw8jv6bdBeEHY+rxFEYz/WaiWWPTCC8LChZ9Q9RZUTOyCvDdeEHJ71drL6o43b0Ftq+6VYxJc8ciXp2L1F37IwSkAuOXVS3BgaApS55TfInzg00ORmoLMSwBww0urIDMFpbcAEpZ8OMeXpmDfQQBwzbNj/N6cUHUUANzzbi03I+oAAUx5stRCfIH6Eql/ZPXfVL3Q1LcK9c1OfbuOcOCoH5kRDn31tiVC4xWhdVRvfiO07xEuIFGuUBEugVGusZfQj28NImRviDLNnQAAAABJRU5ErkJggg==\">\".\n",
        "When you click the \"Run cell\" button, the code in that cell will run\n",
        "and when it finishes, a green check mark appears next to the \"Run\n",
        "cell\" button\".  You need to wait for the code in that cell to finish\n",
        "before \"running\" the next cell."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4kkvU97kDjYh",
      "metadata": {
        "id": "4kkvU97kDjYh"
      },
      "source": [
        "### 1.2 - Particulars of this notebook\n",
        "\n",
        "This notebook was designed to run in Google Colab and to analyse\n",
        "images in Google Drive.  As such, it requires a Google account.\n",
        "\n",
        "You must run the cells on this notebook one after the other since\n",
        "each cell is dependent on the results of the previous cell."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yLHvmZjF5HWk",
      "metadata": {
        "id": "yLHvmZjF5HWk"
      },
      "source": [
        "### 1.3 - GPU access\n",
        "\n",
        "A GPU is not required to run this program but without a GPU it will\n",
        "run much slower.  Depending on the amount of data to analyse, it\n",
        "might not be sensible to use it without a GPU>\n",
        "\n",
        "By default, this notebook will run with a GPU.  However, it is\n",
        "possible that you were not allocated one, typically because you've\n",
        "used up all your GPU resources.  You can confirm this, and possibly\n",
        "change it, manually.  To do that, navigate to \"Edit\" -> \"Notebook\n",
        "Settings\" and select \"GPU\" from the \"Hardware Accelerator\" menu."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y7ZIaFAD1Org",
      "metadata": {
        "id": "y7ZIaFAD1Org"
      },
      "source": [
        "## 2 - Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tKauGGpqIi83",
      "metadata": {
        "id": "tKauGGpqIi83"
      },
      "source": [
        "### 2.1 - Check for GPU access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5h91qABuhv__",
      "metadata": {
        "cellView": "form",
        "id": "5h91qABuhv__"
      },
      "outputs": [],
      "source": [
        "#@markdown By default, this notebook will run with a GPU.  However, it\n",
        "#@markdown is possible that you were not allocated one.  If you get a\n",
        "#@markdown message saying that you do not have access to a GPU,\n",
        "#@markdown navigate to \"Edit\" -> \"Notebook Settings\" and select \"GPU\"\n",
        "#@markdown from the \"Hardware Accelerator\" menu.  If you change it,\n",
        "#@markdown you need to run this cell again.\n",
        "\n",
        "# We do this before everything else, namely before installing\n",
        "# detectron2 (which takes a lot of time), to identify early the case\n",
        "# of accidentally running this without a GPU.\n",
        "import torch.cuda\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    USE_GPU = True\n",
        "    print(\"You are using this GPU:\")\n",
        "    print(\n",
        "        \"GPU %d: %s (%d GB)\"\n",
        "        % (\n",
        "            torch.cuda.current_device(),\n",
        "            torch.cuda.get_device_name(),\n",
        "            torch.cuda.get_device_properties(\n",
        "                torch.cuda.current_device()\n",
        "            ).total_memory\n",
        "            * 1e-9,\n",
        "        )\n",
        "    )\n",
        "else:\n",
        "    USE_GPU = False\n",
        "    print(\"You are NOT connected to a GPU\")\n",
        "    print(\"Consider reconnecting to a runtime with GPU access.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U744F4c3s2Yp",
      "metadata": {
        "id": "U744F4c3s2Yp"
      },
      "source": [
        "### 2.2 - Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HYJHIkdn3Z1J",
      "metadata": {
        "cellView": "form",
        "id": "HYJHIkdn3Z1J"
      },
      "outputs": [],
      "source": [
        "#@markdown This step can take a few of minutes to finish.\n",
        "\n",
        "# Detectron2 is not available on PyPI, we have to install it from\n",
        "# their git repos.\n",
        "\n",
        "# Using `pip install --quiet` is not enough, it still prints out a\n",
        "# mysterious \"Preparing metadata (setup.py)\" message which is why we\n",
        "# redirect stdout to `/dev/null`.  Important messages should go to\n",
        "# stderr anyway.\n",
        "!pip install --quiet git+https://github.com/facebookresearch/detectron2.git > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rmMI8QbZVnUf",
      "metadata": {
        "id": "rmMI8QbZVnUf"
      },
      "source": [
        "### 2.3 - Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hF_7RBxmDCTx",
      "metadata": {
        "cellView": "form",
        "id": "hF_7RBxmDCTx",
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "#@markdown When the model detects something, that detection is\n",
        "#@markdown made with a confidence score between 0 and 100%.\n",
        "#@markdown Detections with a confidence score lower than the selected\n",
        "#@markdown threshold will be discarded.\n",
        "\n",
        "CONFIDENCE_THRESHOLD = 50  #@param {type: \"slider\", min: 0, max: 100, step: 1}\n",
        "CONFIDENCE_THRESHOLD /= 100.0\n",
        "\n",
        "# In the future we can make these options but at the moment we only have\n",
        "# these anyway.\n",
        "DETECTRON2_CONFIG = \"https://thor.robots.ox.ac.uk/staging/env-dante/mask-rcnn-R-50-FPN-D526v2-2024-03-12.py\"\n",
        "MODEL_CKPT = \"https://thor.robots.ox.ac.uk/staging/env-dante/mask-rcnn-R-50-FPN-D526v2-2024-03-12.pth\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hF_7RBxmDCTx",
      "metadata": {
        "id": "hF_7RBxmDCTx"
      },
      "source": [
        "### 2.4 - Load dependencies and configure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iimL6Db6gmbb",
      "metadata": {
        "cellView": "form",
        "id": "iimL6Db6gmbb"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@markdown This cell prepares the detector to run.  This is the place\n",
        "#@markdown to make changes to the code if you want (but you should not\n",
        "#@markdown need to).\n",
        "\n",
        "import logging\n",
        "import time\n",
        "\n",
        "import PIL.Image\n",
        "import detectron2.checkpoint\n",
        "import detectron2.config\n",
        "import detectron2.data\n",
        "import detectron2.data.catalog\n",
        "import detectron2.data.detection_utils\n",
        "import detectron2.data.transforms\n",
        "import detectron2.structures.masks\n",
        "import detectron2.utils.visualizer\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data\n",
        "\n",
        "import google.colab.output\n",
        "import google.colab.files\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "_logger = logging.getLogger()\n",
        "logging.basicConfig()\n",
        "\n",
        "\n",
        "class Detectron2DatasetFromFilelist(torch.utils.data.Dataset):\n",
        "    def __init__(self, fpath_list):\n",
        "        super().__init__()\n",
        "        self._fpath_list = fpath_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._fpath_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\"file_name\": self._fpath_list[idx]}\n",
        "\n",
        "\n",
        "def build_model(cfg):\n",
        "    model = detectron2.config.instantiate(cfg.model)\n",
        "    model = model.to(cfg.train.device)\n",
        "    checkpointer = detectron2.checkpoint.DetectionCheckpointer(model)\n",
        "    checkpointer.load(cfg.train.init_checkpoint)\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_thing_colours(metadata, thing_name_to_colour_name):\n",
        "    thing_colours = {}\n",
        "    for i, thing_name in enumerate(metadata.thing_classes):\n",
        "        colour_name = thing_name_to_colour_name[thing_name]\n",
        "        rgb = tuple([x / 255.0 for x in PIL.ImageColor.getrgb(colour_name)])\n",
        "        thing_colours[i] = rgb\n",
        "    return thing_colours\n",
        "\n",
        "\n",
        "def pred_classes_to_colours(pred_classes, metadata):\n",
        "    return [metadata.thing_colors[i] for i in pred_classes.tolist()]\n",
        "\n",
        "\n",
        "def pred_classes_to_labels(pred_classes, metadata):\n",
        "    return [metadata.thing_classes[i] for i in pred_classes.tolist()]\n",
        "\n",
        "\n",
        "def pred_boxes_to_masks(boxes):\n",
        "    \"\"\"Convert Boxes to PolygonMasks because the Visualizer only shows\n",
        "    boxes boundaries but want to \"fill\" the boxes.\n",
        "    \"\"\"\n",
        "    masks = []\n",
        "    for box in np.asarray(boxes.to(\"cpu\")):\n",
        "        masks.append([np.array([\n",
        "            box[0], box[3],\n",
        "            box[2], box[3],\n",
        "            box[2], box[1],\n",
        "            box[0], box[1]\n",
        "        ])])\n",
        "    return detectron2.structures.masks.PolygonMasks(masks)\n",
        "\n",
        "\n",
        "def transform_boxes(augmentations, original_width, original_height, boxes):\n",
        "    \"\"\"Convert Boxes coordinates from one image size to another.\"\"\"\n",
        "    aug_input = detectron2.data.transforms.AugInput(\n",
        "        np.ndarray((original_width, original_height)), boxes=boxes.to(\"cpu\")\n",
        "    )\n",
        "    transform = augmentations(aug_input)  # in place transform\n",
        "    del transform\n",
        "    return detectron2.structures.Boxes(aug_input.boxes).to(boxes.device)\n",
        "\n",
        "\n",
        "def show_instance_predictions(\n",
        "    input, output, augmentations, metadata, score_thresh\n",
        "):\n",
        "    instances = output[\"instances\"].to(\"cpu\")\n",
        "    # The model saw a resized/transformed image (input[\"image\"] ---\n",
        "    # the transformation would have been applied by the dataloader).\n",
        "    # The output predicted boxes are relative to the original image\n",
        "    # size though.  Because we are showing the predictions on top of\n",
        "    # the resized image we need to transform the boxes.  We could show\n",
        "    # the boxes on the original image but: 1) we'd have to read the\n",
        "    # image again; ad 2) showing the resized image highlights any\n",
        "    # issues caused by the image transform.\n",
        "    boxes = transform_boxes(\n",
        "        augmentations,\n",
        "        input[\"width\"],\n",
        "        input[\"height\"],\n",
        "        instances.pred_boxes\n",
        "    )\n",
        "\n",
        "    wanted = instances.scores > score_thresh\n",
        "    boxes = boxes[wanted]\n",
        "    masks = pred_boxes_to_masks(boxes)\n",
        "\n",
        "    img = input[\"image\"].numpy().transpose(1, 2, 0)\n",
        "    vis = detectron2.utils.visualizer.Visualizer(\n",
        "        img[:, :, ::-1],\n",
        "        metadata=metadata,\n",
        "        instance_mode=detectron2.utils.visualizer.ColorMode.SEGMENTATION,\n",
        "    )\n",
        "    vis_out = vis.overlay_instances(\n",
        "        boxes=boxes,\n",
        "        masks=masks,\n",
        "        labels=pred_classes_to_labels(\n",
        "            instances.pred_classes[wanted], metadata\n",
        "        ),\n",
        "        assigned_colors=pred_classes_to_colours(\n",
        "            instances.pred_classes[wanted], metadata\n",
        "        )\n",
        "    )\n",
        "    cv2_imshow(vis_out.get_image()[:, :, ::-1])\n",
        "\n",
        "\n",
        "cfg = detectron2.config.LazyConfig.load(\n",
        "    detectron2.utils.file_io.PathManager.get_local_path(DETECTRON2_CONFIG)\n",
        ")\n",
        "cfg.train.init_checkpoint = MODEL_CKPT\n",
        "if USE_GPU:\n",
        "    cfg.train.device = \"cuda\"\n",
        "else:\n",
        "    cfg.train.device = \"cpu\"\n",
        "\n",
        "metadata = detectron2.data.catalog.MetadataCatalog.get(\n",
        "    cfg.dataloader.test.dataset.names[0]\n",
        ")\n",
        "\n",
        "metadata.set(\n",
        "    thing_colors=build_thing_colours(\n",
        "        metadata,\n",
        "        {\n",
        "            \"graphic\": \"blue\",\n",
        "            \"initial-capital\": \"magenta\",\n",
        "            \"manicules\": \"lime\",\n",
        "            \"page-number\": \"purple\",\n",
        "            \"poem\": \"green\",\n",
        "            \"running-header\": \"red\",\n",
        "            \"section-header\": \"orange\",\n",
        "            \"sideletter\": \"brown\",\n",
        "            \"sidenote\": \"yellow\",\n",
        "            \"unpainted-guideletter\": \"violet\",\n",
        "            \"catchword-signature\": \"cyan\",\n",
        "        }\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "model = build_model(cfg)\n",
        "model = model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AXRwfL1NAw6O",
      "metadata": {
        "id": "AXRwfL1NAw6O"
      },
      "source": [
        "## 3 - Run Detector"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "H4Rw3Bv7RBYi",
      "metadata": {
        "id": "H4Rw3Bv7RBYi"
      },
      "source": [
        "### 3.1 - Upload Images and Run Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0FDT_4TUPzzW",
      "metadata": {
        "cellView": "form",
        "id": "0FDT_4TUPzzW"
      },
      "outputs": [],
      "source": [
        "#@markdown When you run this cell, a \"Browse...\" button will appear at\n",
        "#@markdown the bottom of the cell.  When you press it, a dialog to\n",
        "#@markdown upload files will appear.  Select any number of images.\n",
        "#@markdown When all selected images finish uploading, they will be\n",
        "#@markdown evaluated one at a time, and the detection results\n",
        "#@markdown displayed.\n",
        "\n",
        "google.colab.output.no_vertical_scroll()\n",
        "\n",
        "uploaded = google.colab.files.upload()\n",
        "dataset = Detectron2DatasetFromFilelist(list(uploaded.keys()))\n",
        "dataset_mapper = detectron2.config.instantiate(cfg.dataloader.test.mapper)\n",
        "dataloader = detectron2.data.build_detection_test_loader(\n",
        "    dataset, mapper=dataset_mapper, batch_size=1,\n",
        ")\n",
        "\n",
        "for inputs in dataloader:\n",
        "    with torch.no_grad():\n",
        "        start_compute_time = time.perf_counter()\n",
        "        outputs = model(inputs)\n",
        "        compute_time = time.perf_counter() - start_compute_time\n",
        "        _logger.debug(\"Inference time: %f seconds\", compute_time)\n",
        "    for input, output in zip(inputs, outputs):\n",
        "        show_instance_predictions(\n",
        "            input,\n",
        "            output,\n",
        "            dataset_mapper.augmentations,\n",
        "            metadata,\n",
        "            CONFIDENCE_THRESHOLD\n",
        "        )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
