{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "blOJ1buw83T9",
      "metadata": {
        "id": "blOJ1buw83T9"
      },
      "source": [
        "# Envisioning Dante - Graphics Detector"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yLERLQAN3pM0",
      "metadata": {
        "id": "yLERLQAN3pM0"
      },
      "source": [
        "## 1 - Read Me First\n",
        "\n",
        "This project is a [Jupyter](https://jupyter.org/) notebook and was\n",
        "designed to run in [Google\n",
        "Colab](https://colab.research.google.com/).  If you are not reading\n",
        "this notebook in Google Colab, click\n",
        "[here](https://colab.research.google.com/github/ox-vgg/demo-notebooks/blob/main/detectors/envdante-detector.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-tfDPTizFHUi",
      "metadata": {
        "id": "-tfDPTizFHUi"
      },
      "source": [
        "### 1.1 - What is, and how to use, a Jupyter notebook\n",
        "\n",
        "A Jupyter notebook is a series of \"cells\".  Each cell contains\n",
        "either text (like this one) or code (like others below).  A cell\n",
        "that contains code will have a \"Run cell\" button on the left side\n",
        "like this \"<img height=\"18rem\" alt=\"The 'Run cell' button in Colab\"\n",
        "src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAQAAAD9CzEMAAABTklEQVRYw+2XMU7DMBRAX6ss3VA7VV25AFNWzsDQXoAzVDlBKw6QDJwhTO3OCVjaka0VXVKJDUVC4jOgiMHYcRx9S0j9f7XfS5x8+xsu8R9iQEpGyY4TgnBiR0lGyqA/fMaaI2LJI2tm4fAxObUV3mRNzjgEP+fcCm/yzLwbPKHwhjdZkPjiR2w64wVhw8jv6bdBeEHY+rxFEYz/WaiWWPTCC8LChZ9Q9RZUTOyCvDdeEHJ71drL6o43b0Ftq+6VYxJc8ciXp2L1F37IwSkAuOXVS3BgaApS55TfInzg00ORmoLMSwBww0urIDMFpbcAEpZ8OMeXpmDfQQBwzbNj/N6cUHUUANzzbi03I+oAAUx5stRCfIH6Eql/ZPXfVL3Q1LcK9c1OfbuOcOCoH5kRDn31tiVC4xWhdVRvfiO07xEuIFGuUBEugVGusZfQj28NImRviDLNnQAAAABJRU5ErkJggg==\">\".\n",
        "When you click the \"Run cell\" button, the code in that cell will run\n",
        "and when it finishes, a green check mark appears next to the \"Run\n",
        "cell\" button\".  You need to wait for the code in that cell to finish\n",
        "before \"running\" the next cell."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4kkvU97kDjYh",
      "metadata": {
        "id": "4kkvU97kDjYh"
      },
      "source": [
        "### 1.2 - Particulars of this notebook\n",
        "\n",
        "This notebook was designed to run in Google Colab and to analyse\n",
        "images in Google Drive.  As such, it requires a Google account.\n",
        "\n",
        "You must run the cells on this notebook one after the other since\n",
        "each cell is dependent on the results of the previous cell."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yLHvmZjF5HWk",
      "metadata": {
        "id": "yLHvmZjF5HWk"
      },
      "source": [
        "### 1.3 - GPU access\n",
        "\n",
        "A GPU is not required to run this program but without a GPU it will\n",
        "run much slower.  Depending on the amount of data to analyse, it\n",
        "might not be sensible to use it without a GPU>\n",
        "\n",
        "By default, this notebook will run with a GPU.  However, it is\n",
        "possible that you were not allocated one, typically because you've\n",
        "used up all your GPU resources.  You can confirm this, and possibly\n",
        "change it, manually.  To do that, navigate to \"Edit\" -> \"Notebook\n",
        "Settings\" and select \"GPU\" from the \"Hardware Accelerator\" menu."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y7ZIaFAD1Org",
      "metadata": {
        "id": "y7ZIaFAD1Org"
      },
      "source": [
        "## 2 - Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tKauGGpqIi83",
      "metadata": {
        "id": "tKauGGpqIi83"
      },
      "source": [
        "### 2.1 - Check for GPU access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5h91qABuhv__",
      "metadata": {
        "cellView": "form",
        "id": "5h91qABuhv__"
      },
      "outputs": [],
      "source": [
        "#@markdown By default, this notebook will run with a GPU.  However, it\n",
        "#@markdown is possible that you were not allocated one.  If you get a\n",
        "#@markdown message saying that you do not have access to a GPU,\n",
        "#@markdown navigate to \"Edit\" -> \"Notebook Settings\" and select \"GPU\"\n",
        "#@markdown from the \"Hardware Accelerator\" menu.  If you change it,\n",
        "#@markdown you need to run this cell again.\n",
        "\n",
        "# We do this before everything else, namely before installing\n",
        "# detectron2 (which takes a lot of time), to identify early the case\n",
        "# of accidentally running this without a GPU.\n",
        "import torch.cuda\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    USE_GPU = True\n",
        "    print(\"You are using this GPU:\")\n",
        "    print(\n",
        "        \"GPU %d: %s (%d GB)\"\n",
        "        % (\n",
        "            torch.cuda.current_device(),\n",
        "            torch.cuda.get_device_name(),\n",
        "            torch.cuda.get_device_properties(\n",
        "                torch.cuda.current_device()\n",
        "            ).total_memory\n",
        "            * 1e-9,\n",
        "        )\n",
        "    )\n",
        "else:\n",
        "    USE_GPU = False\n",
        "    print(\"You are NOT connected to a GPU\")\n",
        "    print(\"Consider reconnecting to a runtime with GPU access.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U744F4c3s2Yp",
      "metadata": {
        "id": "U744F4c3s2Yp"
      },
      "source": [
        "### 2.2 - Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HYJHIkdn3Z1J",
      "metadata": {
        "cellView": "form",
        "id": "HYJHIkdn3Z1J"
      },
      "outputs": [],
      "source": [
        "#@markdown This step can take a few of minutes to finish.\n",
        "\n",
        "# Detectron2 is not available on PyPI, we have to install it from\n",
        "# their git repos.\n",
        "\n",
        "# Using `pip install --quiet` is not enough, it still prints out a\n",
        "# mysterious \"Preparing metadata (setup.py)\" message which is why we\n",
        "# redirect stdout to `/dev/null`.  Important messages should go to\n",
        "# stderr anyway.\n",
        "!pip install --quiet git+https://github.com/facebookresearch/detectron2.git > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rmMI8QbZVnUf",
      "metadata": {
        "id": "rmMI8QbZVnUf"
      },
      "source": [
        "### 2.3 - Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hF_7RBxmDCTx",
      "metadata": {
        "cellView": "form",
        "id": "hF_7RBxmDCTx",
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "#@markdown When the model detects something, that detection is\n",
        "#@markdown made with a confidence score between 0 and 100%.\n",
        "#@markdown Detections with a confidence score lower than the selected\n",
        "#@markdown threshold will be discarded.\n",
        "\n",
        "CONFIDENCE_THRESHOLD = 50  #@param {type: \"slider\", min: 0, max: 100, step: 1}\n",
        "CONFIDENCE_THRESHOLD /= 100.0\n",
        "\n",
        "# In the future we can make these options but at the moment we only have\n",
        "# these anyway.\n",
        "DETECTRON2_CONFIG = \"https://thor.robots.ox.ac.uk/staging/env-dante/mask-rcnn-R-50-FPN-D526v2-2024-03-12.py\"\n",
        "MODEL_CKPT = \"https://thor.robots.ox.ac.uk/staging/env-dante/mask-rcnn-R-50-FPN-D526v2-2024-03-12.pth\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hF_7RBxmDCTx",
      "metadata": {
        "id": "hF_7RBxmDCTx"
      },
      "source": [
        "### 2.4 - Load dependencies and configure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iimL6Db6gmbb",
      "metadata": {
        "cellView": "form",
        "id": "iimL6Db6gmbb",
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "\n",
        "#@markdown This cell prepares the detector to run.  This is the place\n",
        "#@markdown to make changes to the code if you want (but you should not\n",
        "#@markdown need to).\n",
        "\n",
        "import logging\n",
        "\n",
        "import PIL.Image\n",
        "import detectron2.checkpoint\n",
        "import detectron2.config\n",
        "import detectron2.data\n",
        "import detectron2.data.catalog\n",
        "import detectron2.data.detection_utils\n",
        "import detectron2.data.transforms\n",
        "import detectron2.structures.masks\n",
        "import detectron2.utils.visualizer\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import google.colab.output\n",
        "import google.colab.files\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "_logger = logging.getLogger()\n",
        "logging.basicConfig()\n",
        "\n",
        "\n",
        "class Predictor:\n",
        "    \"\"\"Simple end to end detection predictor given a LazyConfig.\"\"\"\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        self.cfg = cfg\n",
        "        self.model = detectron2.config.instantiate(cfg.model)\n",
        "        self.model = self.model.to(cfg.train.device)\n",
        "        checkpointer = detectron2.checkpoint.DetectionCheckpointer(self.model)\n",
        "        checkpointer.load(cfg.train.init_checkpoint)\n",
        "        self.augmentations = detectron2.data.transforms.AugmentationList(\n",
        "            [\n",
        "                detectron2.config.instantiate(x)\n",
        "                for x in cfg.dataloader.test.mapper.augmentations\n",
        "            ]\n",
        "        )\n",
        "        self.model.eval()\n",
        "\n",
        "    def __call__(self, original_image):\n",
        "        with torch.no_grad():\n",
        "            # Apply pre-processing to image.\n",
        "            height, width = original_image.shape[:2]\n",
        "            image = self.augmentations(\n",
        "                detectron2.data.transforms.AugInput(original_image)\n",
        "            ).apply_image(original_image)\n",
        "            image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
        "            inputs = {\"image\": image, \"height\": height, \"width\": width}\n",
        "            predictions = self.model([inputs])[0]\n",
        "            return predictions\n",
        "\n",
        "\n",
        "def build_thing_colours(metadata, thing_name_to_colour_name):\n",
        "    thing_colours = {}\n",
        "    for i, thing_name in enumerate(metadata.thing_classes):\n",
        "        colour_name = thing_name_to_colour_name[thing_name]\n",
        "        rgb = tuple([x / 255.0 for x in PIL.ImageColor.getrgb(colour_name)])\n",
        "        thing_colours[i] = rgb\n",
        "    return thing_colours\n",
        "\n",
        "\n",
        "def pred_classes_to_colours(pred_classes, metadata):\n",
        "    return [metadata.thing_colors[i] for i in pred_classes.tolist()]\n",
        "\n",
        "\n",
        "def pred_classes_to_labels(pred_classes, metadata):\n",
        "    return [metadata.thing_classes[i] for i in pred_classes.tolist()]\n",
        "\n",
        "\n",
        "def pred_boxes_to_masks(boxes):\n",
        "    masks = []\n",
        "    for box in np.asarray(boxes.to(\"cpu\")):\n",
        "        masks.append([np.array([\n",
        "            box[0], box[3],\n",
        "            box[2], box[3],\n",
        "            box[2], box[1],\n",
        "            box[0], box[1]\n",
        "        ])])\n",
        "    return detectron2.structures.masks.PolygonMasks(masks)\n",
        "\n",
        "\n",
        "def show_instance_predictions(img, predictions, metadata, score_thresh):\n",
        "    v = detectron2.utils.visualizer.Visualizer(\n",
        "        img[:, :, ::-1],\n",
        "        metadata=metadata,\n",
        "        instance_mode=detectron2.utils.visualizer.ColorMode.SEGMENTATION,\n",
        "    )\n",
        "    wanted = predictions[\"instances\"].scores > score_thresh\n",
        "    out = v.overlay_instances(\n",
        "        boxes=predictions[\"instances\"].pred_boxes[wanted].to(\"cpu\"),\n",
        "        masks=pred_boxes_to_masks(predictions[\"instances\"].pred_boxes[wanted]),\n",
        "        labels=pred_classes_to_labels(\n",
        "            predictions[\"instances\"].pred_classes[wanted], metadata\n",
        "        ),\n",
        "        assigned_colors=pred_classes_to_colours(\n",
        "            predictions[\"instances\"].pred_classes[wanted], metadata\n",
        "        )\n",
        "    )\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "\n",
        "\n",
        "cfg = detectron2.config.LazyConfig.load(\n",
        "    detectron2.utils.file_io.PathManager.get_local_path(DETECTRON2_CONFIG)\n",
        ")\n",
        "cfg.train.init_checkpoint = MODEL_CKPT\n",
        "if USE_GPU:\n",
        "    cfg.train.device = \"cuda\"\n",
        "else:\n",
        "    cfg.train.device = \"cpu\"\n",
        "\n",
        "metadata = detectron2.data.catalog.MetadataCatalog.get(cfg.dataloader.test.dataset.names[0])\n",
        "\n",
        "metadata.set(\n",
        "    thing_colors=build_thing_colours(\n",
        "        metadata,\n",
        "        {\n",
        "            \"graphic\": \"blue\",\n",
        "            \"initial-capital\": \"magenta\",\n",
        "            \"manicules\": \"lime\",\n",
        "            \"page-number\": \"purple\",\n",
        "            \"poem\": \"green\",\n",
        "            \"running-header\": \"red\",\n",
        "            \"section-header\": \"orange\",\n",
        "            \"sideletter\": \"brown\",\n",
        "            \"sidenote\": \"yellow\",\n",
        "            \"unpainted-guideletter\": \"violet\",\n",
        "            \"catchword-signature\": \"cyan\",\n",
        "        }\n",
        "    )\n",
        ")\n",
        "\n",
        "predictor = Predictor(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AXRwfL1NAw6O",
      "metadata": {
        "id": "AXRwfL1NAw6O"
      },
      "source": [
        "## 3 - Run Detector"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "H4Rw3Bv7RBYi",
      "metadata": {
        "id": "H4Rw3Bv7RBYi"
      },
      "source": [
        "### 3.1 - Upload Images and Run Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0FDT_4TUPzzW",
      "metadata": {
        "cellView": "form",
        "id": "0FDT_4TUPzzW"
      },
      "outputs": [],
      "source": [
        "#@markdown When you run this cell, a \"Browse...\" button will appear at\n",
        "#@markdown the bottom of the cell.  When you press it, a dialog to\n",
        "#@markdown upload files will appear.  Select any number of images.\n",
        "#@markdown When all selected images finish uploading, they will be\n",
        "#@markdown evaluated one at a time, and the detection results\n",
        "#@markdown displayed.\n",
        "\n",
        "google.colab.output.no_vertical_scroll()\n",
        "\n",
        "uploaded = google.colab.files.upload()\n",
        "for fpath in uploaded.keys():\n",
        "    try:\n",
        "        img = detectron2.data.detection_utils.read_image(\n",
        "            fpath,\n",
        "            cfg.dataloader.train.mapper.image_format\n",
        "        )\n",
        "    except Exception as exc:\n",
        "        _logger.error(\"Failed to read %s: %s\", fpath, exc)\n",
        "    predictions = predictor(img)\n",
        "    show_instance_predictions(\n",
        "        img, predictions, metadata, CONFIDENCE_THRESHOLD\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
